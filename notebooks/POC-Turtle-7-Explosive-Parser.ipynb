{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC-Turtle-7: \"Dumb Explosive Parser\"\n",
    "This is a continuation of proof-of-concept (POC) experiments in unsupervised language learning (ULL), the OpenCog project hosted on [GitHub](https://github.com/opencog/language-learning/tree/master/notebooks).   \n",
    "Previous results are shared as [static html copies of Jupyter notebooks](http://88.99.210.144/data/clustering_2018/html/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-16 05:42:32 UTC :: module_path: /home/obaskov/language-learning\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path: sys.path.append(module_path)\n",
    "from src.utl.utl import UTC\n",
    "from src.utl.turtle import html_table\n",
    "print(UTC(), ':: module_path:', module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Settings, parameters, data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory /home/obaskov/language-learning/output/Turtle-7-2018-03-15/ exists\n"
     ]
    }
   ],
   "source": [
    "prj_dir = '../output/Turtle-7-2018-03-15/'  # project directory \n",
    "prefix = ''     # all project files will start with this prefix\n",
    "verbose = 'max' # printed comments: 'none', 'min', 'max'\n",
    "log = {'project': 'POC-Turtle-7: Explosive Parser'}\n",
    "\n",
    "if not os.path.exists(prj_dir):\n",
    "    os.makedirs(prj_dir)\n",
    "    print('Project directory created:', module_path + prj_dir[2:])\n",
    "else: print('Project directory', module_path + prj_dir[2:], 'exists')\n",
    "path = module_path + prj_dir[2:]        # path to store vectors\n",
    "tmpath = path  # module_path + '/tmp/'  # path for temporary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: /home/obaskov/language-learning/data/poc-turtle-sentences.txt\n",
      "- \"Turtle\" language corpus:\n",
      "1. tuna isa fish.\n",
      "2. herring isa fish.\n",
      "3. tuna has fin.\n",
      "4. herring has fin.\n",
      "5. parrot isa bird.\n",
      "6. eagle isa bird.\n",
      "7. parrot has wing.\n",
      "8. eagle has wing.\n",
      "9. fin isa extremity.\n",
      "10. wing isa extremity.\n",
      "11. fin has scale.\n",
      "12. wing has feather.\n"
     ]
    }
   ],
   "source": [
    "input_file = '../data/poc-turtle-sentences.txt'\n",
    "if os.path.isfile(input_file):\n",
    "    print('Data file:', module_path + input_file[2:],)\n",
    "    log.update({'input_file': module_path + input_file[2:]})\n",
    "    if verbose == 'max':\n",
    "        print('- \"Turtle\" language corpus:')\n",
    "        with open(input_file, 'r') as f: \n",
    "            lines = f.read().splitlines() # [0:2]\n",
    "        for i,line in enumerate(lines): \n",
    "            if len(line) > 0: print(str(i+1)+'. '+line)    \n",
    "else: print('No data file', module_path + input_file[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Parse \"synthetic\" disjuncts from sentences.\n",
    "We create pseudo-disjuncts for each word in each sentence taking all af the sentence words as its left and right neighbour words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 disjuncts parsed from ../data/poc-turtle-sentences.txt\n"
     ]
    }
   ],
   "source": [
    "def explosive_parser(input_file, lw='LEFT-WALL', dot=True, verbose='none'):  # 80316 Turtle-7\n",
    "    djs = pd.DataFrame(columns=['word','disjunct','count'])\n",
    "    i = 0\n",
    "    with open(input_file, 'r') as f: sentences = f.readlines() # [0:1]\n",
    "    for j,sentence in enumerate(sentences):\n",
    "        if len(sentence) > 1:\n",
    "            sentence = sentence.rstrip()\n",
    "            if dot == True:\n",
    "                if sentence[-2]== ' .': continue\n",
    "                elif sentence[-1] == '.': sentence = sentence[:-1] + ' .'\n",
    "                else : sentence += ' .'\n",
    "            else:\n",
    "                if sentence[-2] == ' .': sentence = sentence[:-2]\n",
    "                elif sentence[-1] == '.': sentence = sentence[:-1]\n",
    "            if type(lw) == str and lw != 'none' and lw != '':\n",
    "                sentence = lw + ' ' + sentence\n",
    "            words = sentence.split()\n",
    "            for k,word in enumerate(words):\n",
    "                if k == 0:\n",
    "                    for l in range(k+1, len(words)):\n",
    "                        disjunct = words[l] + '+'\n",
    "                        count = 1.0/(l-k)\n",
    "                        djs.loc[i] = [word, disjunct, count]\n",
    "                        i += 1\n",
    "                else:\n",
    "                    for m in range(0, k):  # single left disjuncts\n",
    "                        disjunct = words[m] + '-'\n",
    "                        count = 1.0/(k-m)\n",
    "                        djs.loc[i] = [word, disjunct, count]\n",
    "                        i += 1\n",
    "                    for n in range(k+1, len(words)):  # single right disjuncts\n",
    "                        disjunct = words[n] + '+'\n",
    "                        count = 1.0/(n-k)\n",
    "                        djs.loc[i] = [word, disjunct, count]\n",
    "                        i += 1\n",
    "        #-elif verbose == 'max': print('Empty line - EOF?', input_file)\n",
    "    return djs\n",
    "\n",
    "left_wall = 'LEFT-WALL' # Left wall symbol, '', 'none' - don't use Left-Wall\n",
    "parses = explosive_parser(input_file, left_wall, dot=True, verbose='max')\n",
    "if verbose != 'none': print(len(parses),'disjuncts parsed from', input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>disjunct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LEFT-WALL</td>\n",
       "      <td>tuna+</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LEFT-WALL</td>\n",
       "      <td>isa+</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LEFT-WALL</td>\n",
       "      <td>fish+</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LEFT-WALL</td>\n",
       "      <td>.+</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tuna</td>\n",
       "      <td>LEFT-WALL-</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tuna</td>\n",
       "      <td>isa+</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tuna</td>\n",
       "      <td>fish+</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tuna</td>\n",
       "      <td>.+</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>isa</td>\n",
       "      <td>LEFT-WALL-</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>isa</td>\n",
       "      <td>tuna-</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>isa</td>\n",
       "      <td>fish+</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>isa</td>\n",
       "      <td>.+</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word    disjunct     count\n",
       "0   LEFT-WALL       tuna+  1.000000\n",
       "1   LEFT-WALL        isa+  0.500000\n",
       "2   LEFT-WALL       fish+  0.333333\n",
       "3   LEFT-WALL          .+  0.250000\n",
       "4        tuna  LEFT-WALL-  1.000000\n",
       "5        tuna        isa+  1.000000\n",
       "6        tuna       fish+  0.500000\n",
       "7        tuna          .+  0.333333\n",
       "8         isa  LEFT-WALL-  0.500000\n",
       "9         isa       tuna-  1.000000\n",
       "10        isa       fish+  1.000000\n",
       "11        isa          .+  0.500000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parses.head(12) \n",
    "# parses # uncomment to display 240-row DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 words and 28 unique disjuncts form 116 unique word-disjunct pairs\n"
     ]
    }
   ],
   "source": [
    "disjuncts = parses.groupby(['word','disjunct'], as_index=False).sum() \\\n",
    "    .sort_values(by=['count','word','disjunct'], ascending=[False,True,True]) \\\n",
    "    .reset_index(drop=True)\n",
    "dj_number = len(set(disjuncts['disjunct'].tolist()))\n",
    "word_number = len(set(disjuncts['word'].tolist()))\n",
    "if verbose != 'none': print(word_number, 'words and', dj_number, \\\n",
    "    'unique disjuncts form', len(disjuncts),'unique word-disjunct pairs') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>disjunct</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.</td>\n",
       "      <td>LEFT-WALL-</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.</td>\n",
       "      <td>has-</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>isa-</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LEFT-WALL</td>\n",
       "      <td>.+</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LEFT-WALL</td>\n",
       "      <td>has+</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LEFT-WALL</td>\n",
       "      <td>isa+</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>has</td>\n",
       "      <td>.+</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>has</td>\n",
       "      <td>LEFT-WALL-</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>isa</td>\n",
       "      <td>.+</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>isa</td>\n",
       "      <td>LEFT-WALL-</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>.</td>\n",
       "      <td>fin-</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>.</td>\n",
       "      <td>wing-</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word    disjunct     count\n",
       "0           .  LEFT-WALL-  3.000000\n",
       "1           .        has-  3.000000\n",
       "2           .        isa-  3.000000\n",
       "3   LEFT-WALL          .+  3.000000\n",
       "4   LEFT-WALL        has+  3.000000\n",
       "5   LEFT-WALL        isa+  3.000000\n",
       "6         has          .+  3.000000\n",
       "7         has  LEFT-WALL-  3.000000\n",
       "8         isa          .+  3.000000\n",
       "9         isa  LEFT-WALL-  3.000000\n",
       "10          .        fin-  2.666667\n",
       "11          .       wing-  2.666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disjuncts.head(12)\n",
    "# disjuncts # uncomment to display 116-row DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Learn multi-germ-multi-disjunct lexical entries\n",
    "We cluster words and disjuncts to form unique multi-germ-multi-disjunct lexical entries, following the Link Grammar rules. Actually the entries are low-level Link Grammar rules, but Link Grammar would not accept word-based disjuncts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>germs</th>\n",
       "      <th>disjuncts</th>\n",
       "      <th>counts</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C01</th>\n",
       "      <td>[.]</td>\n",
       "      <td>[LEFT-WALL-, bird-, eagle-, extremity-, feathe...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>C01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C02</th>\n",
       "      <td>[LEFT-WALL]</td>\n",
       "      <td>[.+, bird+, eagle+, extremity+, feather+, fin+...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>C02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C03</th>\n",
       "      <td>[bird]</td>\n",
       "      <td>[.+, LEFT-WALL-, eagle-, isa-, parrot-]</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>C03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C04</th>\n",
       "      <td>[eagle, parrot]</td>\n",
       "      <td>[.+, LEFT-WALL-, bird+, has+, isa+, wing+]</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>C04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C05</th>\n",
       "      <td>[extremity]</td>\n",
       "      <td>[.+, LEFT-WALL-, fin-, isa-, wing-]</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>C05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C06</th>\n",
       "      <td>[feather]</td>\n",
       "      <td>[.+, LEFT-WALL-, has-, wing-]</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>C06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C07</th>\n",
       "      <td>[fin]</td>\n",
       "      <td>[.+, LEFT-WALL-, extremity+, has+, has-, herri...</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>C07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C08</th>\n",
       "      <td>[fish]</td>\n",
       "      <td>[.+, LEFT-WALL-, herring-, isa-, tuna-]</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>C08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C09</th>\n",
       "      <td>[has]</td>\n",
       "      <td>[.+, LEFT-WALL-, eagle-, feather+, fin+, fin-,...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>C09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10</th>\n",
       "      <td>[herring, tuna]</td>\n",
       "      <td>[.+, LEFT-WALL-, fin+, fish+, has+, isa+]</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>C10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C11</th>\n",
       "      <td>[isa]</td>\n",
       "      <td>[.+, LEFT-WALL-, bird+, eagle-, extremity+, fi...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>C11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C12</th>\n",
       "      <td>[scale]</td>\n",
       "      <td>[.+, LEFT-WALL-, fin-, has-]</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>C12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C13</th>\n",
       "      <td>[wing]</td>\n",
       "      <td>[.+, LEFT-WALL-, eagle-, extremity+, feather+,...</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>C13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               germs                                          disjuncts  \\\n",
       "C01              [.]  [LEFT-WALL-, bird-, eagle-, extremity-, feathe...   \n",
       "C02      [LEFT-WALL]  [.+, bird+, eagle+, extremity+, feather+, fin+...   \n",
       "C03           [bird]            [.+, LEFT-WALL-, eagle-, isa-, parrot-]   \n",
       "C04  [eagle, parrot]         [.+, LEFT-WALL-, bird+, has+, isa+, wing+]   \n",
       "C05      [extremity]                [.+, LEFT-WALL-, fin-, isa-, wing-]   \n",
       "C06        [feather]                      [.+, LEFT-WALL-, has-, wing-]   \n",
       "C07            [fin]  [.+, LEFT-WALL-, extremity+, has+, has-, herri...   \n",
       "C08           [fish]            [.+, LEFT-WALL-, herring-, isa-, tuna-]   \n",
       "C09            [has]  [.+, LEFT-WALL-, eagle-, feather+, fin+, fin-,...   \n",
       "C10  [herring, tuna]          [.+, LEFT-WALL-, fin+, fish+, has+, isa+]   \n",
       "C11            [isa]  [.+, LEFT-WALL-, bird+, eagle-, extremity+, fi...   \n",
       "C12          [scale]                       [.+, LEFT-WALL-, fin-, has-]   \n",
       "C13           [wing]  [.+, LEFT-WALL-, eagle-, extremity+, feather+,...   \n",
       "\n",
       "        counts cluster  \n",
       "C01  25.000000     C01  \n",
       "C02  25.000000     C02  \n",
       "C03   5.666667     C03  \n",
       "C04  11.333333     C04  \n",
       "C05   5.666667     C05  \n",
       "C06   2.833333     C06  \n",
       "C07  11.333333     C07  \n",
       "C08   5.666667     C08  \n",
       "C09  18.000000     C09  \n",
       "C10  11.333333     C10  \n",
       "C11  18.000000     C11  \n",
       "C12   2.833333     C12  \n",
       "C13  11.333333     C13  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.link_grammar.turtle import entries2clusters, lexical_entries\n",
    "stalks = entries2clusters(lexical_entries(disjuncts))\n",
    "stalks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display word-based Link Grammar rules (not valid for LG parser)\n",
    "# from src.link_grammar.turtle import entries2rules\n",
    "# display(html_table([['Cluster','Germs','','','Disjuncts']] + entries2rules(stalks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Learn Link Grammar rules from multi-germ-multi-disjunct lexical entries\n",
    "The next step from multi-germ-multi-disjunct lexical entries to Link Grammar rules is replacing words in disjuncts with cluster identificators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>germs</th>\n",
       "      <th>disjuncts</th>\n",
       "      <th>counts</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C01</th>\n",
       "      <td>[.]</td>\n",
       "      <td>[C02C01-, C03C01-, C04C01-, C05C01-, C06C01-, ...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>C01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C02</th>\n",
       "      <td>[LEFT-WALL]</td>\n",
       "      <td>[C02C01+, C02C03+, C02C04+, C02C05+, C02C06+, ...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>C02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C03</th>\n",
       "      <td>[bird]</td>\n",
       "      <td>[C02C03-, C03C01+, C04C03-, C11C03-]</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>C03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C04</th>\n",
       "      <td>[eagle, parrot]</td>\n",
       "      <td>[C02C04-, C04C01+, C04C03+, C04C09+, C04C11+, ...</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>C04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C05</th>\n",
       "      <td>[extremity]</td>\n",
       "      <td>[C02C05-, C05C01+, C07C05-, C11C05-, C13C05-]</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>C05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C06</th>\n",
       "      <td>[feather]</td>\n",
       "      <td>[C02C06-, C06C01+, C09C06-, C13C06-]</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>C06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C07</th>\n",
       "      <td>[fin]</td>\n",
       "      <td>[C02C07-, C07C01+, C07C05+, C07C09+, C07C11+, ...</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>C07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C08</th>\n",
       "      <td>[fish]</td>\n",
       "      <td>[C02C08-, C08C01+, C10C08-, C11C08-]</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>C08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C09</th>\n",
       "      <td>[has]</td>\n",
       "      <td>[C02C09-, C04C09-, C07C09-, C09C01+, C09C06+, ...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>C09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10</th>\n",
       "      <td>[herring, tuna]</td>\n",
       "      <td>[C02C10-, C10C01+, C10C07+, C10C08+, C10C09+, ...</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>C10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C11</th>\n",
       "      <td>[isa]</td>\n",
       "      <td>[C02C11-, C04C11-, C07C11-, C10C11-, C11C01+, ...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>C11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C12</th>\n",
       "      <td>[scale]</td>\n",
       "      <td>[C02C12-, C07C12-, C09C12-, C12C01+]</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>C12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C13</th>\n",
       "      <td>[wing]</td>\n",
       "      <td>[C02C13-, C04C13-, C09C13-, C13C01+, C13C05+, ...</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>C13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               germs                                          disjuncts  \\\n",
       "C01              [.]  [C02C01-, C03C01-, C04C01-, C05C01-, C06C01-, ...   \n",
       "C02      [LEFT-WALL]  [C02C01+, C02C03+, C02C04+, C02C05+, C02C06+, ...   \n",
       "C03           [bird]               [C02C03-, C03C01+, C04C03-, C11C03-]   \n",
       "C04  [eagle, parrot]  [C02C04-, C04C01+, C04C03+, C04C09+, C04C11+, ...   \n",
       "C05      [extremity]      [C02C05-, C05C01+, C07C05-, C11C05-, C13C05-]   \n",
       "C06        [feather]               [C02C06-, C06C01+, C09C06-, C13C06-]   \n",
       "C07            [fin]  [C02C07-, C07C01+, C07C05+, C07C09+, C07C11+, ...   \n",
       "C08           [fish]               [C02C08-, C08C01+, C10C08-, C11C08-]   \n",
       "C09            [has]  [C02C09-, C04C09-, C07C09-, C09C01+, C09C06+, ...   \n",
       "C10  [herring, tuna]  [C02C10-, C10C01+, C10C07+, C10C08+, C10C09+, ...   \n",
       "C11            [isa]  [C02C11-, C04C11-, C07C11-, C10C11-, C11C01+, ...   \n",
       "C12          [scale]               [C02C12-, C07C12-, C09C12-, C12C01+]   \n",
       "C13           [wing]  [C02C13-, C04C13-, C09C13-, C13C01+, C13C05+, ...   \n",
       "\n",
       "        counts cluster  \n",
       "C01  25.000000     C01  \n",
       "C02  25.000000     C02  \n",
       "C03   5.666667     C03  \n",
       "C04  11.333333     C04  \n",
       "C05   5.666667     C05  \n",
       "C06   2.833333     C06  \n",
       "C07  11.333333     C07  \n",
       "C08   5.666667     C08  \n",
       "C09  18.000000     C09  \n",
       "C10  11.333333     C10  \n",
       "C11  18.000000     C11  \n",
       "C12   2.833333     C12  \n",
       "C13  11.333333     C13  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.link_grammar.turtle import disjuncts2clusters\n",
    "rules = disjuncts2clusters(stalks)  # DataFrame\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Cluster</td><td>Germs</td><td>L</td><td>R</td><td>Disjuncts</td></tr><tr><td>C01</td><td>['.']</td><td>[]</td><td>[]</td><td>['C02C01-', 'C03C01-', 'C04C01-', 'C05C01-', 'C06C01-', 'C07C01-', 'C08C01-', 'C09C01-', 'C10C01-', 'C11C01-', 'C12C01-', 'C13C01-']</td></tr><tr><td>C02</td><td>['LEFT-WALL']</td><td>[]</td><td>[]</td><td>['C02C01+', 'C02C03+', 'C02C04+', 'C02C05+', 'C02C06+', 'C02C07+', 'C02C08+', 'C02C09+', 'C02C10+', 'C02C11+', 'C02C12+', 'C02C13+']</td></tr><tr><td>C03</td><td>['bird']</td><td>[]</td><td>[]</td><td>['C02C03-', 'C03C01+', 'C04C03-', 'C11C03-']</td></tr><tr><td>C04</td><td>['eagle', 'parrot']</td><td>[]</td><td>[]</td><td>['C02C04-', 'C04C01+', 'C04C03+', 'C04C09+', 'C04C11+', 'C04C13+']</td></tr><tr><td>C05</td><td>['extremity']</td><td>[]</td><td>[]</td><td>['C02C05-', 'C05C01+', 'C07C05-', 'C11C05-', 'C13C05-']</td></tr><tr><td>C06</td><td>['feather']</td><td>[]</td><td>[]</td><td>['C02C06-', 'C06C01+', 'C09C06-', 'C13C06-']</td></tr><tr><td>C07</td><td>['fin']</td><td>[]</td><td>[]</td><td>['C02C07-', 'C07C01+', 'C07C05+', 'C07C09+', 'C07C11+', 'C07C12+', 'C09C07-', 'C10C07-']</td></tr><tr><td>C08</td><td>['fish']</td><td>[]</td><td>[]</td><td>['C02C08-', 'C08C01+', 'C10C08-', 'C11C08-']</td></tr><tr><td>C09</td><td>['has']</td><td>[]</td><td>[]</td><td>['C02C09-', 'C04C09-', 'C07C09-', 'C09C01+', 'C09C06+', 'C09C07+', 'C09C12+', 'C09C13+', 'C10C09-', 'C13C09-']</td></tr><tr><td>C10</td><td>['herring', 'tuna']</td><td>[]</td><td>[]</td><td>['C02C10-', 'C10C01+', 'C10C07+', 'C10C08+', 'C10C09+', 'C10C11+']</td></tr><tr><td>C11</td><td>['isa']</td><td>[]</td><td>[]</td><td>['C02C11-', 'C04C11-', 'C07C11-', 'C10C11-', 'C11C01+', 'C11C03+', 'C11C05+', 'C11C08+', 'C13C11-']</td></tr><tr><td>C12</td><td>['scale']</td><td>[]</td><td>[]</td><td>['C02C12-', 'C07C12-', 'C09C12-', 'C12C01+']</td></tr><tr><td>C13</td><td>['wing']</td><td>[]</td><td>[]</td><td>['C02C13-', 'C04C13-', 'C09C13-', 'C13C01+', 'C13C05+', 'C13C06+', 'C13C09+', 'C13C11+']</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.link_grammar.turtle import entries2rules\n",
    "lg_rule_list = entries2rules(rules)\n",
    "display(html_table([['Cluster','Germs','L','R','Disjuncts']] + lg_rule_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Save Link Grammar dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% POC Turtle Link Grammar v.0.7 2018-03-16 05:42:33 UTC\n",
      "<dictionary-version-number>: V0v0v7+;\n",
      "<dictionary-locale>: EN4us+;\n",
      "\n",
      "% C01\n",
      "\".\":\n",
      "(C02C01-) or (C03C01-) or (C04C01-) or (C05C01-) or (C06C01-) or (C07C01-) or (C08C01-) or (C09C01-) or (C10C01-) or (C11C01-) or (C12C01-) or (C13C01-);\n",
      "\n",
      "% C02\n",
      "\"LEFT-WALL\":\n",
      "(C02C01+) or (C02C03+) or (C02C04+) or (C02C05+) or (C02C06+) or (C02C07+) or (C02C08+) or (C02C09+) or (C02C10+) or (C02C11+) or (C02C12+) or (C02C13+);\n",
      "\n",
      "% C03\n",
      "\"bird\":\n",
      "(C02C03-) or (C03C01+) or (C04C03-) or (C11C03-);\n",
      "\n",
      "% C04\n",
      "\"eagle\" \"parrot\":\n",
      "(C02C04-) or (C04C01+) or (C04C03+) or (C04C09+) or (C04C11+) or (C04C13+);\n",
      "\n",
      "% C05\n",
      "\"extremity\":\n",
      "(C02C05-) or (C05C01+) or (C07C05-) or (C11C05-) or (C13C05-);\n",
      "\n",
      "% C06\n",
      "\"feather\":\n",
      "(C02C06-) or (C06C01+) or (C09C06-) or (C13C06-);\n",
      "\n",
      "% C07\n",
      "\"fin\":\n",
      "(C02C07-) or (C07C01+) or (C07C05+) or (C07C09+) or (C07C11+) or (C07C12+) or (C09C07-) or (C10C07-);\n",
      "\n",
      "% C08\n",
      "\"fish\":\n",
      "(C02C08-) or (C08C01+) or (C10C08-) or (C11C08-);\n",
      "\n",
      "% C09\n",
      "\"has\":\n",
      "(C02C09-) or (C04C09-) or (C07C09-) or (C09C01+) or (C09C06+) or (C09C07+) or (C09C12+) or (C09C13+) or (C10C09-) or (C13C09-);\n",
      "\n",
      "% C10\n",
      "\"herring\" \"tuna\":\n",
      "(C02C10-) or (C10C01+) or (C10C07+) or (C10C08+) or (C10C09+) or (C10C11+);\n",
      "\n",
      "% C11\n",
      "\"isa\":\n",
      "(C02C11-) or (C04C11-) or (C07C11-) or (C10C11-) or (C11C01+) or (C11C03+) or (C11C05+) or (C11C08+) or (C13C11-);\n",
      "\n",
      "% C12\n",
      "\"scale\":\n",
      "(C02C12-) or (C07C12-) or (C09C12-) or (C12C01+);\n",
      "\n",
      "% C13\n",
      "\"wing\":\n",
      "(C02C13-) or (C04C13-) or (C09C13-) or (C13C01+) or (C13C05+) or (C13C06+) or (C13C09+) or (C13C11+);\n",
      "\n",
      "UNKNOWN-WORD: XXX+;\n",
      "\n",
      "% 13 word clusters, 13 Link Grammar rules.\n",
      "% Link Grammar file saved to: /home/obaskov/language-learning/output/Turtle-7-2018-03-15/poc-turtle_13C_2018-03-16_0007.4.0.dict\n"
     ]
    }
   ],
   "source": [
    "from src.link_grammar.turtle import save_link_grammar\n",
    "lg_file_string = save_link_grammar(lg_rule_list, path)\n",
    "for line in lg_file_string.splitlines(): print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Test the dictionary with Link Grammar parser\n",
    "The dictionary was tested with an external CLI Pyton API to the Link Grammar parser on the server. The code is in early beta. \n",
    "```\n",
    "tuna isa fish.\n",
    "`/home/obaskov/data/lg/poc-turtle_13C_2018-03-15_0007: Found 4 linkages (4 had no P.P. violations)`\n",
    "\n",
    "    +-C02C10+            \n",
    "    |       |            \n",
    "LEFT-WALL tuna [isa] [fish.] \n",
    "\n",
    "\n",
    "    +----C02C11---+      \n",
    "    |             |      \n",
    "LEFT-WALL [tuna] isa [fish.] \n",
    "\n",
    "\n",
    "    +-------C02C08-------+    \n",
    "    |                    |    \n",
    "LEFT-WALL [tuna] [isa] fish [.] \n",
    "\n",
    "\n",
    "    +----------C02C01---------+\n",
    "    |                         |\n",
    "LEFT-WALL [tuna] [isa] [fish] . \n",
    "\n",
    "\n",
    "\n",
    "herring isa fish. : Found 4 linkages (4 had no P.P. violations)\n",
    "\n",
    "    +-C02C10-+              \n",
    "    |        |              \n",
    "LEFT-WALL herring [isa] [fish.] \n",
    "\n",
    "\n",
    "    +-----C02C11-----+      \n",
    "    |                |      \n",
    "LEFT-WALL [herring] isa [fish.] \n",
    "\n",
    "\n",
    "    +---------C02C08--------+    \n",
    "    |                       |    \n",
    "LEFT-WALL [herring] [isa] fish [.] \n",
    "\n",
    "\n",
    "    +-----------C02C01-----------+\n",
    "    |                            |\n",
    "LEFT-WALL [herring] [isa] [fish] . \n",
    "\n",
    "\n",
    "\n",
    "tuna has fin. : Found 4 linkages (4 had no P.P. violations)`\n",
    "\n",
    "    +-C02C10+            \n",
    "    |       |            \n",
    "LEFT-WALL tuna [has] [fin.] \n",
    "\n",
    "\n",
    "    +----C02C09---+      \n",
    "    |             |      \n",
    "LEFT-WALL [tuna] has [fin.] \n",
    "\n",
    "\n",
    "    +-------C02C07------+    \n",
    "    |                   |    \n",
    "LEFT-WALL [tuna] [has] fin [.] \n",
    "\n",
    "\n",
    "    +---------C02C01---------+\n",
    "    |                        |\n",
    "LEFT-WALL [tuna] [has] [fin] . \n",
    "\n",
    "\n",
    "\n",
    "herring has fin. : Found 4 linkages (4 had no P.P. violations)`\n",
    "\n",
    "    +-C02C10-+              \n",
    "    |        |              \n",
    "LEFT-WALL herring [has] [fin.] \n",
    "\n",
    "\n",
    "    +-----C02C09-----+      \n",
    "    |                |      \n",
    "LEFT-WALL [herring] has [fin.] \n",
    "\n",
    "\n",
    "    +--------C02C07--------+    \n",
    "    |                      |    \n",
    "LEFT-WALL [herring] [has] fin [.] \n",
    "\n",
    "\n",
    "    +-----------C02C01----------+\n",
    "    |                           |\n",
    "LEFT-WALL [herring] [has] [fin] . \n",
    "\n",
    "\n",
    "parrot isa bird. : Found 4 linkages (4 had no P.P. violations)`\n",
    "\n",
    "    +-C02C04-+             \n",
    "    |        |             \n",
    "LEFT-WALL parrot [isa] [bird.] \n",
    "\n",
    "\n",
    "    +-----C02C11----+      \n",
    "    |               |      \n",
    "LEFT-WALL [parrot] isa [bird.] \n",
    "\n",
    "\n",
    "    +--------C02C03--------+    \n",
    "    |                      |    \n",
    "LEFT-WALL [parrot] [isa] bird [.] \n",
    "\n",
    "\n",
    "    +-----------C02C01----------+\n",
    "    |                           |\n",
    "LEFT-WALL [parrot] [isa] [bird] . \n",
    "\n",
    "\n",
    "eagle isa bird. : Found 4 linkages (4 had no P.P. violations)`\n",
    "\n",
    "    +-C02C04+             \n",
    "    |       |             \n",
    "LEFT-WALL eagle [isa] [bird.] \n",
    "\n",
    "\n",
    "    +----C02C11----+      \n",
    "    |              |      \n",
    "LEFT-WALL [eagle] isa [bird.] \n",
    "\n",
    "\n",
    "    +--------C02C03-------+    \n",
    "    |                     |    \n",
    "LEFT-WALL [eagle] [isa] bird [.] \n",
    "\n",
    "\n",
    "    +----------C02C01----------+\n",
    "    |                          |\n",
    "LEFT-WALL [eagle] [isa] [bird] . \n",
    "\n",
    "\n",
    "parrot has wing. : Found 4 linkages (4 had no P.P. violations)`\n",
    "\n",
    "    +-C02C04-+             \n",
    "    |        |             \n",
    "LEFT-WALL parrot [has] [wing.] \n",
    "\n",
    "\n",
    "    +-----C02C09----+      \n",
    "    |               |      \n",
    "LEFT-WALL [parrot] has [wing.] \n",
    "\n",
    "\n",
    "    +--------C02C13--------+    \n",
    "    |                      |    \n",
    "LEFT-WALL [parrot] [has] wing [.] \n",
    "\n",
    "\n",
    "    +-----------C02C01----------+\n",
    "    |                           |\n",
    "LEFT-WALL [parrot] [has] [wing] . \n",
    "\n",
    "\n",
    "\n",
    "eagle has wing. : Found 4 linkages (4 had no P.P. violations)`\n",
    "\n",
    "    +-C02C04+             \n",
    "    |       |             \n",
    "LEFT-WALL eagle [has] [wing.] \n",
    "\n",
    "\n",
    "    +----C02C09----+      \n",
    "    |              |      \n",
    "LEFT-WALL [eagle] has [wing.] \n",
    "\n",
    "\n",
    "    +--------C02C13-------+    \n",
    "    |                     |    \n",
    "LEFT-WALL [eagle] [has] wing [.] \n",
    "\n",
    "\n",
    "    +----------C02C01----------+\n",
    "    |                          |\n",
    "LEFT-WALL [eagle] [has] [wing] . \n",
    "\n",
    "\n",
    "\n",
    "fin isa extremity. : Found 4 linkages (4 had no P.P. violations)`\n",
    "\n",
    "    +C02C07+               \n",
    "    |      |               \n",
    "LEFT-WALL fin [isa] [extremity.] \n",
    "\n",
    "\n",
    "    +---C02C11---+         \n",
    "    |            |         \n",
    "LEFT-WALL [fin] isa [extremity.] \n",
    "\n",
    "\n",
    "    +--------C02C05-------+       \n",
    "    |                     |       \n",
    "LEFT-WALL [fin] [isa] extremity [.] \n",
    "\n",
    "\n",
    "    +------------C02C01-----------+\n",
    "    |                             |\n",
    "LEFT-WALL [fin] [isa] [extremity] . \n",
    "\n",
    "\n",
    "wing isa extremity. : Found 4 linkages (4 had no P.P. violations)`\n",
    "\n",
    "    +-C02C13+               \n",
    "    |       |               \n",
    "LEFT-WALL wing [isa] [extremity.] \n",
    "\n",
    "\n",
    "    +----C02C11---+         \n",
    "    |             |         \n",
    "LEFT-WALL [wing] isa [extremity.] \n",
    "\n",
    "\n",
    "    +--------C02C05--------+       \n",
    "    |                      |       \n",
    "LEFT-WALL [wing] [isa] extremity [.] \n",
    "\n",
    "\n",
    "    +------------C02C01------------+\n",
    "    |                              |\n",
    "LEFT-WALL [wing] [isa] [extremity] . \n",
    "\n",
    "\n",
    "\n",
    "fin has scale. : Found 4 linkages (4 had no P.P. violations)`\n",
    "\n",
    "    +C02C07+             \n",
    "    |      |             \n",
    "LEFT-WALL fin [has] [scale.] \n",
    "\n",
    "\n",
    "    +---C02C09---+       \n",
    "    |            |       \n",
    "LEFT-WALL [fin] has [scale.] \n",
    "\n",
    "\n",
    "    +-------C02C12------+     \n",
    "    |                   |     \n",
    "LEFT-WALL [fin] [has] scale [.] \n",
    "\n",
    "\n",
    "    +----------C02C01---------+\n",
    "    |                         |\n",
    "LEFT-WALL [fin] [has] [scale] . \n",
    "\n",
    "\n",
    "\n",
    "wing has feather. : Found 4 linkages (4 had no P.P. violations)`\n",
    "\n",
    "    +-C02C13+              \n",
    "    |       |              \n",
    "LEFT-WALL wing [has] [feather.] \n",
    "\n",
    "\n",
    "    +----C02C09---+        \n",
    "    |             |        \n",
    "LEFT-WALL [wing] has [feather.] \n",
    "\n",
    "\n",
    "    +--------C02C06-------+      \n",
    "    |                     |      \n",
    "LEFT-WALL [wing] [has] feather [.] \n",
    "\n",
    "\n",
    "    +-----------C02C01-----------+\n",
    "    |                            |\n",
    "LEFT-WALL [wing] [has] [feather] . \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_P.S. Looks like a total fail..._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 Link Grammar for a dataset with removed punctuation\n",
    "Let's collect the grammar learning pipeline in a short summary and test it on the same dataset parsed without ###LEFT-WALL### and period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 unique disjuncts form 62 unique word-disjunct pairs from 72 parsed items\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>Cluster</td><td>Germs</td><td></td><td></td><td>Disjuncts</td></tr><tr><td>C01</td><td>['bird']</td><td>[]</td><td>[]</td><td>['C02C01-', 'C09C01-']</td></tr><tr><td>C02</td><td>['eagle', 'parrot']</td><td>[]</td><td>[]</td><td>['C02C01+', 'C02C07+', 'C02C09+', 'C02C11+']</td></tr><tr><td>C03</td><td>['extremity']</td><td>[]</td><td>[]</td><td>['C05C03-', 'C09C03-', 'C11C03-']</td></tr><tr><td>C04</td><td>['feather']</td><td>[]</td><td>[]</td><td>['C07C04-', 'C11C04-']</td></tr><tr><td>C05</td><td>['fin']</td><td>[]</td><td>[]</td><td>['C05C03+', 'C05C07+', 'C05C09+', 'C05C10+', 'C07C05-', 'C08C05-']</td></tr><tr><td>C06</td><td>['fish']</td><td>[]</td><td>[]</td><td>['C08C06-', 'C09C06-']</td></tr><tr><td>C07</td><td>['has']</td><td>[]</td><td>[]</td><td>['C02C07-', 'C05C07-', 'C07C04+', 'C07C05+', 'C07C10+', 'C07C11+', 'C08C07-', 'C11C07-']</td></tr><tr><td>C08</td><td>['herring', 'tuna']</td><td>[]</td><td>[]</td><td>['C08C05+', 'C08C06+', 'C08C07+', 'C08C09+']</td></tr><tr><td>C09</td><td>['isa']</td><td>[]</td><td>[]</td><td>['C02C09-', 'C05C09-', 'C08C09-', 'C09C01+', 'C09C03+', 'C09C06+', 'C11C09-']</td></tr><tr><td>C10</td><td>['scale']</td><td>[]</td><td>[]</td><td>['C05C10-', 'C07C10-']</td></tr><tr><td>C11</td><td>['wing']</td><td>[]</td><td>[]</td><td>['C02C11-', 'C07C11-', 'C11C03+', 'C11C04+', 'C11C07+', 'C11C09+']</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pipeline(input_file, left_wall='', period=False, verbose='none'):\n",
    "    parses = explosive_parser(input_file, left_wall, dot=False, verbose='max')\n",
    "    disjuncts = parses.groupby(['word','disjunct'], as_index=False).sum() \\\n",
    "        .sort_values(by=['count','word','disjunct'], ascending=[False,True,True]) \\\n",
    "        .reset_index(drop=True)\n",
    "    dj_number = len(set(disjuncts['disjunct'].tolist()))\n",
    "    if verbose != 'none': print(dj_number, 'unique disjuncts form', \\\n",
    "        len(disjuncts),'unique word-disjunct pairs from', len(parses), 'parsed items') \n",
    "    dfg = lexical_entries(disjuncts)\n",
    "    dfc = entries2clusters(dfg)\n",
    "    rules = disjuncts2clusters(dfc)\n",
    "    lg_rule_list = entries2rules(rules)\n",
    "    return lg_rule_list\n",
    "\n",
    "lg_rule_list = pipeline(input_file, left_wall='', period=False, verbose='max')\n",
    "display(html_table([['Cluster','Germs','','','Disjuncts']] + lg_rule_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% POC Turtle Link Grammar v.0.7 2018-03-16 05:42:33 UTC\n",
      "<dictionary-version-number>: V0v0v7+;\n",
      "<dictionary-locale>: EN4us+;\n",
      "\n",
      "% C01\n",
      "\"bird\":\n",
      "(C02C01-) or (C09C01-);\n",
      "\n",
      "% C02\n",
      "\"eagle\" \"parrot\":\n",
      "(C02C01+) or (C02C07+) or (C02C09+) or (C02C11+);\n",
      "\n",
      "% C03\n",
      "\"extremity\":\n",
      "(C05C03-) or (C09C03-) or (C11C03-);\n",
      "\n",
      "% C04\n",
      "\"feather\":\n",
      "(C07C04-) or (C11C04-);\n",
      "\n",
      "% C05\n",
      "\"fin\":\n",
      "(C05C03+) or (C05C07+) or (C05C09+) or (C05C10+) or (C07C05-) or (C08C05-);\n",
      "\n",
      "% C06\n",
      "\"fish\":\n",
      "(C08C06-) or (C09C06-);\n",
      "\n",
      "% C07\n",
      "\"has\":\n",
      "(C02C07-) or (C05C07-) or (C07C04+) or (C07C05+) or (C07C10+) or (C07C11+) or (C08C07-) or (C11C07-);\n",
      "\n",
      "% C08\n",
      "\"herring\" \"tuna\":\n",
      "(C08C05+) or (C08C06+) or (C08C07+) or (C08C09+);\n",
      "\n",
      "% C09\n",
      "\"isa\":\n",
      "(C02C09-) or (C05C09-) or (C08C09-) or (C09C01+) or (C09C03+) or (C09C06+) or (C11C09-);\n",
      "\n",
      "% C10\n",
      "\"scale\":\n",
      "(C05C10-) or (C07C10-);\n",
      "\n",
      "% C11\n",
      "\"wing\":\n",
      "(C02C11-) or (C07C11-) or (C11C03+) or (C11C04+) or (C11C07+) or (C11C09+);\n",
      "\n",
      "UNKNOWN-WORD: XXX+;\n",
      "\n",
      "% 11 word clusters, 11 Link Grammar rules.\n",
      "% Link Grammar file saved to: /home/obaskov/language-learning/output/Turtle-7-2018-03-15/poc-turtle_11C_2018-03-16_0007.4.0.dict\n"
     ]
    }
   ],
   "source": [
    "lg_file_string = save_link_grammar(lg_rule_list, path)\n",
    "for line in lg_file_string.splitlines(): print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link Grammar parsing tests with the learned 11-rule dictionary\n",
    "```\n",
    "tuna isa fish : Found 2 linkages (2 had no P.P. violations)`\n",
    "\n",
    "  +C08C09+      \n",
    "  |      |      \n",
    "tuna    isa [fish] \n",
    "\n",
    "\n",
    "  +--C08C06--+\n",
    "  |          |\n",
    "tuna [isa] fish \n",
    "\n",
    "\n",
    "herring isa fish : Found 2 linkages (2 had no P.P. violations)`\n",
    "\n",
    "   +C08C09+      \n",
    "   |      |      \n",
    "herring  isa [fish] \n",
    "\n",
    "\n",
    "   +---C08C06---+\n",
    "   |            |\n",
    "herring [isa] fish \n",
    "\n",
    "\n",
    "tuna has fin : Found 2 linkages (2 had no P.P. violations)`\n",
    "\n",
    "  +C08C07+     \n",
    "  |      |     \n",
    "tuna    has [fin] \n",
    "\n",
    "\n",
    "  +--C08C05-+\n",
    "  |         |\n",
    "tuna [has] fin \n",
    "\n",
    "\n",
    "herring has fin : Found 2 linkages (2 had no P.P. violations)`\n",
    "\n",
    "   +C08C07+     \n",
    "   |      |     \n",
    "herring  has [fin] \n",
    "\n",
    "\n",
    "   +---C08C05--+\n",
    "   |           |\n",
    "herring [has] fin \n",
    "\n",
    "\n",
    "parrot isa bird : Found 2 linkages (2 had no P.P. violations)`\n",
    "\n",
    "   +C02C09+      \n",
    "   |      |      \n",
    "parrot   isa [bird] \n",
    "\n",
    "\n",
    "   +---C02C01--+\n",
    "   |           |\n",
    "parrot [isa] bird \n",
    "\n",
    "\n",
    "eagle isa bird : Found 2 linkages (2 had no P.P. violations)`\n",
    "\n",
    "  +C02C09+      \n",
    "  |      |      \n",
    "eagle   isa [bird] \n",
    "\n",
    "\n",
    "  +---C02C01--+\n",
    "  |           |\n",
    "eagle [isa] bird \n",
    "\n",
    "\n",
    "parrot has wing : Found 2 linkages (2 had no P.P. violations)`\n",
    "\n",
    "   +C02C07+      \n",
    "   |      |      \n",
    "parrot   has [wing] \n",
    "\n",
    "\n",
    "   +---C02C11--+\n",
    "   |           |\n",
    "parrot [has] wing \n",
    "\n",
    "\n",
    "eagle has wing : Found 2 linkages (2 had no P.P. violations)`\n",
    "\n",
    "  +C02C07+      \n",
    "  |      |      \n",
    "eagle   has [wing] \n",
    "\n",
    "\n",
    "  +---C02C11--+\n",
    "  |           |\n",
    "eagle [has] wing \n",
    "\n",
    "\n",
    "fin isa extremity : Found 2 linkages (2 had no P.P. violations)`\n",
    "\n",
    " +C05C09+        \n",
    " |      |        \n",
    "fin    isa [extremity] \n",
    "\n",
    "\n",
    " +---C05C03---+\n",
    " |            |\n",
    "fin [isa] extremity \n",
    "\n",
    "\n",
    "wing isa extremity : Found 2 linkages (2 had no P.P. violations)`\n",
    "\n",
    "  +C11C09+        \n",
    "  |      |        \n",
    "wing    isa [extremity] \n",
    "\n",
    "\n",
    "  +---C11C03---+\n",
    "  |            |\n",
    "wing [isa] extremity \n",
    "\n",
    "\n",
    "fin has scale : Found 2 linkages (2 had no P.P. violations)`\n",
    "\n",
    " +C05C07+      \n",
    " |      |      \n",
    "fin    has [scale] \n",
    "\n",
    "\n",
    " +--C05C10--+\n",
    " |          |\n",
    "fin [has] scale \n",
    "\n",
    "\n",
    "wing has feather : Found 2 linkages (2 had no P.P. violations)`\n",
    "\n",
    "  +C11C07+       \n",
    "  |      |       \n",
    "wing    has [feather] \n",
    "\n",
    "\n",
    "  +---C11C04--+\n",
    "  |           |\n",
    "wing [has] feather \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume\n",
    "The first attempt to learn grammar with \"dumb explosive parser\" failed.\n",
    "\n",
    "The Link Grammar dictionaries are shared via [http://88.99.210.144/data/clustering_2018/POC-Turtle-7-2018-03-15/](http://88.99.210.144/data/clustering_2018/POC-Turtle-7-2018-03-15/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
